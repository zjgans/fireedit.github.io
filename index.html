<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG" />
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG" />
  <meta property="og:url" content="URL OF THE WEBSITE" />
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200" />
  <meta property="og:image:height" content="630" />


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>ConsistentID</title>
  <style>
    /* 居中和放大标题 */
    .abstract-title {
      text-align: center;
      /* 文本居中 */
      font-size: 10em;
      /* 设置字体大小 */
    }

    .author-block {
      position: relative;
    }

    .author-block a {
      position: relative;
      /* 让链接相对定位，以便数字在链接之上 */
    }



    .cart-count {
      position: absolute;
      top: -8px;
      right: -8px;
      background-color: rgb(159, 156, 156);
      color: white;
      padding: 2px 4px;
      font-size: 8px;
      border-radius: 50%;
    }
  </style>

  <link rel="icon" type="image/x-icon" href="static\images\titleLogo.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>

<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">ConsistentID:Portrait Generation with Multimodal Fine-Grained
              Identity Preserving</h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
<!--                 <a href="https://jackailab.github.io/" target="_blank">Jiehui Huang</a><span class="cart-count">1</span> -->
                <a  target="_blank">Jiehui Huang</a><span class="cart-count">1</span>
              </span>,
              <span class="author-block">
                <a href="https://scholar.google.com/citations?user=jXLkbw8AAAAJ&hl=zh-CN&oi=sra" target="_blank">Xiao Dong</a><span class="cart-count">2</span>
              </span>,
              <span class="author-block">
                <a target="_blank">Wenhui Song</a><span class="cart-count">1</span>
              </span>,
              <span class="author-block">
                <a target="_blank">Hanhui Li</a><span class="cart-count">1</span>
              </span>,
              <span class="author-block">
                <a target="_blank">Jun Zhou</a><span class="cart-count">1</span>
              </span>,
              <span class="author-block">
                <a target="_blank">Yuhao Cheng</a><span class="cart-count">3</span>
              </span>,
              <span class="author-block">
                <a target="_blank">Shutao Liao</a><span class="cart-count">1</span>
              </span>,
              <span class="author-block">
                <a target="_blank">Long Chen</a><span class="cart-count">3</span>
              </span>,
              <span class="author-block">
                <a target="_blank">Yiqiang Yan</a><span class="cart-count">3</span>
              </span>,
              <span class="author-block">
                <a href="https://shengcailiao.github.io/" target="_blank">Shengcai Liao</a><span
                  class="cart-count">4</span>
              </span>,
              <span class="author-block">
                <a href="https://www.sysu-hcp.net/faculty/xiaodanliang.html" arget="_blank">Xiaodan Liang</a><span
                  class="cart-count">1</span>
              </span>
            </div>

            <div class="is-size-5 publication-authors">
              <span class="author-block">1. Shenzhen Campus of Sun Yat-sen University,</span>
              <span class="author-block">2. Zhuhai Campus of Sun Yat-sen University,</span>
              <span class="author-block">3. Lenovo Research,</span>
              <span class="author-block">4. Inception Institute of Artificial Intelligence</span>
            </div>


            <div class="column has-text-centered">
              <div class="publication-links">
                <!-- Arxiv PDF link -->
                <span class="link-block">
                  <a href="arXiv.pdf" target="_blank" class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                  </a>
                </span>

                <!-- Supplementary PDF link -->
                <span class="link-block">
                  <a  href="https://huggingface.co/spaces/JackAILab/ConsistentID/" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fas fa-play-circle"></i>
                    </span>
                    <span>Demo</span>
                  </a>
                </span>

                <!-- Github link -->
                <span class="link-block">
                  <a href="https://github.com/JackAILab/ConsistentID" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="http://arxiv.org/abs/2404.16771" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                  </a>
                </span>
              </div>
            </div>
          </div>
        </div>
      </div>
    </div>
  </section>

  <!-- Teaser image-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- Your image here -->
        <img src="static\images\teaser.jpg" alt="Teaser Image" width="100%" height="auto">
        <h2 class="subtitle has-text-centered">
          Given some images of input IDs, our ConsistentID can generate diverse personalized ID images based on text
          prompts using only a single image.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser image -->


  <!-- Teaser video-->
  <!-- <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        Your video here
        <source src="\static\PDF\teaser.pdf" type="application/pdf">
        <h2 class="subtitle has-text-centered">
          Given some images of input IDs, our ConsistentID can generate diverse personalized ID images based on text
          prompts using only a single image.
        </h2>
      </div>
    </div>
  </section> -->
  <!-- End teaser video -->

  <!-- Paper abstract -->
  <section class="section hero is-light">
    <div class="container is-max-desktop">
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          <h2 class="title is-3">Abstract</h2>
          <div class="content has-text-justified">
            <p>
              Diffusion-based technologies have made significant strides, particularly in personalized and customized
              facialgeneration.
              However, existing methods face challenges in achieving high-fidelity and detailed identity
              (ID)consistency, primarily
              due to insufficient fine-grained control over facial areas and the lack of a comprehensive strategy for ID
              preservation by fully considering intricate facial details and the overall face.
              To address these limitations, we introduce ConsistentID, an innovative method crafted for
              diverseidentity-preserving
              portrait generation under fine-grained multimodal facial prompts, utilizing only a single reference image.
              ConsistentID comprises two key components: a multimodal facial prompt generator that combines facial
              features,
              corresponding facial descriptions and the overall facial context to enhance precision in facial details,
              and an ID-preservation network optimized through the facial attention localization strategy, aimed at
              preserving
              ID consistency in facial regions. Together, these components significantly enhance the accuracy of ID
              preservation by introducing
              fine-grained multimodal ID information from facial regions.
              To facilitate training of ConsistentID, we present a fine-grained portrait dataset, FGID, with over
              500,000 facial
              images, offering greater diversity and comprehensiveness than existing public facial datasets. % such as
              LAION-Face,
              CelebA, FFHQ, and SFHQ. Experimental results substantiate that our ConsistentID achieves exceptional
              precision and diversity in
              personalized facial generation, surpassing existing methods in the MyStyle dataset.
              Furthermore, while ConsistentID introduces more multimodal ID information, it maintains a fast inference
              speed during
              generation.
            </p>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End paper abstract -->

  <!-- Teaser image-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- Your image here -->
        <h2 class="title is-3 abstract-title">Facial feature details</h2>
        <img src="static\images\FacialCompare.jpg" alt="MY ALT TEXT" />
        <h2 class="subtitle has-text-centered">
          Comparison of facial feature details between our method and existing approaches.
        </h2>
      </div>
    </div>
  </section>
  <!-- End teaser image -->

  <!-- Framework-->
  <section class="hero teaser">
    <div class="container is-max-desktop">
      <div class="hero-body">
        <!-- Your image here -->
        <h2 class="title is-3 abstract-title">Framework</h2>
        <img src="static\images\Framework_page-0001.jpg" alt="Teaser Image" width="100%" height="auto">
        <h2 class="subtitle has-text-centered">
          The overall framework of our proposed ConsistentID.
        </h2>
        <h2>
          The framework comprises two key modules: a multimodal facial ID generator and a purposefully crafted
          ID-preservation
          network. The multimodal facial prompt generator consists of two essential components: a fine-grained
          multimodal feature
          extractor, which focuses on capturing detailed facial information, and a facial ID feature extractor dedicated
          to
          learning facial ID features. On the other hand, the ID-preservation network utilizes both facial textual and
          visual
          prompts, preventing the blending of ID information from different facial regions through the facial attention
          localization strategy. This approach ensures the preservation of ID consistency in the facial regions.
        </h2>
      </div>
    </div>
  </section>
  <!-- End Framework -->


  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <h2 class="title is-3 abstract-title">Application</h2>

      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\Application_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              The comparisons of two downstream applications.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\mix_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Application cases of ConsistentID for identity confusion.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\old_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Application cases of ConsistentID for bringing old photos back to life.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\age_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Application cases of ConsistentID for altering the age attribute of a character.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\sfhq_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Application on SFHQ test set.
            </h2>
          </div>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->






  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <h2 class="title is-3 abstract-title">Comparation</h2>
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\ResultsCompare_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Qualitative comparison of universal recontextualization samples is conducted, comparing our approach with
              other methods using five distinct identities and their corresponding prompts. Our ConsistentID exhibits a
              more powerful capability in high-quality generation, flexible editability, and strong identity fidelity.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\Photomaker_InstantID_Compare_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Qualitative comparison of our model with other models on two special tasks: stylization and action
              instruction.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\compare_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              The comparisons with more fine-tuning-based models.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\IPACompare_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Comparison of ConsistentID with IP-Adapter and its face version variants conditioned on different styles.
            </h2>
          </div>
        </div>
        <div class="item">
          <!-- Your image here -->
          <img src="static\images\All_Model_Vis_page-0001.jpg" alt="MY ALT TEXT" />
          <h2 class="subtitle has-text-centered">
            Visualization in re-contextualization settings. These examples demonstrate the high-identity fidelity and
            text editing
            capability of ConsistentID.
          </h2>
        </div>
      </div>
    </div>
  </section>
  <!-- End image carousel -->

  <!-- Image carousel -->
  <section class="hero is-small">
    <div class="hero-body">
      <h2 class="title is-3 abstract-title">Ablation experiment</h2>
      <div class="container">
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\Vis_AttentionLoss_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Visualized results with or without using attention loss.
            </h2>
          </div>
          <div class="item">
            <!-- Your image here -->
            <img src="static\images\Vis_DelayControl_page-0001.jpg" alt="MY ALT TEXT" />
            <h2 class="subtitle has-text-centered">
              Visualized results under different `merge steps'. `Merge Step' indicates when to start adding facial image
              features to the text prompt.
            </h2>
          </div>
        </div>
      </div>
  </section>
  <!-- End image carousel -->


  <!-- Paper poster -->
  <!-- <section class="hero is-small is-light">
    <div class="hero-body">
      <div class="container">
        <h2 class="title">Poster</h2>

        <iframe src="static/pdfs/sample.pdf" width="100%" height="550">
        </iframe>

      </div>
    </div>
  </section> -->
  <!--End paper poster -->


  <!-- BibTex citation -->
  <!-- <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>BibTex Code Here</code></pre>
    </div>
  </section> -->
  <!--End BibTex citation -->


  <footer class="footer">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">

            <p>
              This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template"
                target="_blank">Academic Project Page Template</a> which was adopted from the <a
                href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
              <br> This website is licensed under a <a rel="license"
                href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
                Commons Attribution-ShareAlike 4.0 International License</a>.
            </p>

          </div>
        </div>
      </div>
    </div>
  </footer>

  <!-- Statcounter tracking code -->

  <!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

  <!-- End of Statcounter Code -->

</body>

</html>
